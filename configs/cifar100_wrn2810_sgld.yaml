# Configuration for CIFAR-100 WideResNet-28-10 SGLD Experiment

data:
  name: cifar100
  root: data/cifar-100-python
  batch_size: 128
  num_workers: 4

model:
  name: wrn_28_10_cifar
  num_classes: 100
  widen_factor: 10
  depth: 28

train:
  epochs: 0  # No pretraining, start sampling directly
  learning_rate: 1e-3
  weight_decay: 1e-4
  optimizer: sgd
  scheduler: cosine

sampler:
  type: sgld
  step_size: 1e-4
  temperature: 1.0
  burn_in: 2000
  thin: 200
  num_samples: 100
  noise_scale: 1.0

out:
  dir: runs/c100_wrn2810_sgld
  save_samples: true
  save_traces: true
